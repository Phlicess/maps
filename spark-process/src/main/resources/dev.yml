# Used only for the spark application name
appName: Map build (development)

# A parquet file of occurrence records
# Hint: Consider using a Hive CTAS query "STORED AS PARQUET" from occurrence_hdfs
sourceFile: /user/hive/warehouse/tim.db/occurrence_map_source_tenth

# The base directory into which HFiles will be stored
targetDirectory: hdfs://nameservice1/tmp/tim_maps

# The max record count allowed before the view is built into a tile pyramid
tilesThreshold: 100000

# Target HBase details
hbase:
  zkQuorum: c1n1.gbif.org,c1n2.gbif.org,c1n3.gbif.org

# Applies only to those map views that have few enough records to be stored as features
pointFeatures:
  numTasks: 200 # controls the parallelism
  tableName: tim_test
  hfileCount: 32

# TilePyramid applies to views where there are more records than the tilesThreshold
# Notes:
#   For hfileCount > 32 you must use -Dhbase.mapreduce.bulkload.max.hfiles.perRegion.perFamily=XXX when bulk loading
tilePyramid:
  tableName: tim_test
  hfileCount: 100
  projections:
    # Web Mercator (e.g. like google maps)
    -  minZoom: 0
       maxZoom: 3
       tileSize: 512
       srs: EPSG:3857
    # WGS84 unprojected
    #-  minZoom: 0
    #   maxZoom: 3
    #   tileSize: 512
    #   srs: EPSG:4326
    # North Pole LAEA (e.g. Arctic)
    -  minZoom: 0
       maxZoom: 3
       tileSize: 512
       srs: EPSG:3575




